---
title: A Note on Sample Size Calculation
author: Xing
date: '2017-12-25'
tags:
  - Experiments
  - Learning
  - R
  - Statistics
output:
  blogdown::html_page:
    toc: true
slug: sample-size
---

This note describes how sample size calculator works. There must be better notes somewhere else, but I find the best notes for me is the note written by myself. 

# How Sample Size is Determined?

First we have to imagine that $N$ participants will be randomly assigned into two groups: Treatment (T) and Control (C) group. Assume that there are equal numbers of participants in each group ($N_T=N_C$). The researcher is interested in testing whether the mean of the distribution $\mu$ in two groups are different. More specifically, the researcher is comparing the two hypotheses:

$$H_0: \mu_T-\mu_C=\mu_0=0$$
$$H_A: \mu_T-\mu_C =\mu_A \neq 0$$

The researcher is interested in the impact of the treatment on variable $x$. Let $X_T$ denote the sample average of the treatment group, and $X_C$ the sample average of the control group. The significance level is defined as $\alpha=Prob(Reject \quad H_0|H_0)$. It can be expressed in the following way: $\alpha = Prob(X_T-X_C\geq v|H_0)$, where $v$ is the critical value. For two-sided test $\frac{\alpha}{2} = Prob(X_T-X_C\geq v|H_0)$. That is, if we want to reject the null hypothesis, the difference $X_T-X_C$ should be large enough. Some simple algebra is needed to derive the critical value:

\[\frac{\alpha}{2}=Prob(\mu_T-\mu_C\geq v|H_0)\]
\[=1-Prob(X_T-X_C\leq v|H_0)\]
\[=1-Prob(\frac{X_T-X_C-\mu_0}{\sigma_N}\leq \frac{v-mu_0}{\sigma_N}|H_0)\]
\[=1-Prob(\frac{X_T-X_C}{\sigma_N}\leq \frac{v}{\sigma_N}|H_0)\](under Null hypothesis $\mu_0=0$)
\[=1-\phi(\frac{v}{\sigma_N})\]($\phi$ is standardized normal distribution function)

Let $z_{1-\frac{\alpha}{2}}=\frac{v}{\sigma_N}$, and then $v=z_{1-\frac{\alpha}{2}} \cdot \sigma_N$.

Since power is defined as the probability of accepting the alternative hypothesis given that the alternative is true $1-\beta=Prob(Accept \quad H_A|H_A)=Prob(X_T-X_C\geq v|H_A)$, which can be expressed as:
\[1-\beta=1-Prob(X_T-X_C\leq z_{1-\frac{\alpha}{2}} \cdot \sigma_N |H_A)\]
\[=1-Prob(\frac{X_T-X_C-\mu_A}{\sigma_N}\leq \frac{z_{1-\frac{\alpha}{2}} \cdot \sigma_N-\mu_A}{\sigma_N}|H_A)\]
\[=1-\phi(\frac{z_{1-\frac{\alpha}{2}} \cdot \sigma_N -\mu_A}{\sigma_N})\]
\[=\phi(\frac{\mu_A}{\sigma_N}-z_{1-\frac{\alpha}{2}})\]
As a result, $z_{1-\beta}=\frac{\mu_A}{\sigma_N}-z_{1-\frac{\alpha}{2}}$. Under the alternative hypothesis, $X_T-X_C \sim N(\mu_A,\sigma^2/n)$. Now suppose the variable of interest is binomial distributed. Then $\sigma_N=\sqrt{X_T(1-X_T)/N_T + X_C(1-X_C)/N_C}$
$$\frac{1}{\sqrt{X_T(1-X_T)/N_T + X_C(1-X_C)/N_C}}= \frac{z_{1-\beta}+z_{1-\frac{\alpha}{2}}}{X_T-X_C}$$
$ \Rightarrow $

$$N_T=N_C=(X_T(1-X_T)+X_C(1-X_C))\cdot (\frac{z_{1-\beta}+z_{1-\frac{\alpha}{2}}}{X_T-X_C})^2$$

# Some R code

Hence, if we want to calculate the sample size, we only need to specify the expected rate/proportion in treatment, the expected rate/proportion in control, power, and the significance level. The code to calculate sample size for binary outcome assuming $\alpha= .05$ is: 
```{r}
## Calculate Sample Size Based on Binary Outcome
SampleSize = function(PropTreat, PropCont, Power){
  N = ((PropTreat*(1-PropTreat)+PropCont*(1-PropCont))*
    ((qnorm(1-.05/2)+qnorm(1-(1-Power)))^2))/((PropTreat-PropCont)^2)
  return(ceilling(N))
}
```

Using the same logic, we can get the formula to calculate the sample size for normally distributed outcome:

```{r}
## Calculate Sample Size Based on Continuous Outcome
## Two sided test at 0.05 significance level
## kappa is the ratio of the sample size in control and treatment
## SDTreat is the standard deviation 
SampleSizeM = function(MeanTreat, MeanCont, SDTreat, SDCont, Power){
  NTreat =(SDTreat^2+SDCont^2)*
    ((qnorm(1-.05/2)+qnorm(1-(1-Power)))/(MeanTreat-MeanCont))^2
  return(ceiling(NTreat))
}
```
# Is it the end of the day if $\alpha = 0.005$?

One concern I had when first saw this [paper](https://www.nature.com/articles/s41562-017-0189-z) by Benjamin et al (2017) on redefining statistical significance. They proposed to **change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries.** That is the proposed p-value is only one tenth of the conventional one!! Suppose the world changed to `p=0.005`. Do we need **10X** more sample? As a researcher without sufficient funding, we care about how much additional sample we need suppose the alternative hypothesis is true. The original paper gave an answer for this question. We can use the function to illustrate the additional sample we need.




