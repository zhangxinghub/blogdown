---
title: U-Shape Test using "Two Lines" - A Simpler Solution for Discrete IV
author: Xing
date: '2018-05-25'
output:
  blogdown::html_page:
    toc: true
slug: u-shape-test-using-two-lines
categories: []
tags:
  - Statistics
  - Data Science
  - Model Selection
---


<div id="TOC">
<ul>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#two-lines-approaches">Two-lines Approaches</a></li>
<li><a href="#issue-with-discrete-dependent-variable">Issue with Discrete Dependent Variable</a></li>
</ul>
</div>

<div id="motivation" class="section level1">
<h1>Motivation</h1>
<p>In this <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3021690">paper</a> by Uri Simonsohn (2017), the author proposed a noval method to test U-Shape relationship. In the literature, the popular way of testing U-shapeness relationship between <code>x</code> and <code>y</code> is to add a quadratic term in the regression <span class="math inline">\(y=\beta_0+\beta_1 x + \beta_2 x^2 +\epsilon\)</span> (<span class="math inline">\(\epsilon\)</span> is an <em>i.i.d</em> noise). If <span class="math inline">\(\beta_1\)</span> is statistitally significant, then the relationship betewen <code>x</code> and <code>y</code> are U-shape. There are plenty of examples in the real world that two variables have such kind of relationship (consider x = amount of sugar in the icecream, and y = the taste). Simonsohn pointed out that using the quadratic regression would lead to high false positive rate.</p>
<p>I am directly borrowing the example he gave in the paper. Suppose the underlying relationship is <span class="math inline">\(y=\log{x} +\epsilon\)</span>, where <span class="math inline">\(x\sim U[0,1]\)</span>. We first simulate the data and have the following plot:</p>
<pre class="r"><code>set.seed(111)
obs = 10000 # Sample Size of Observations
x = runif(n = obs)^2 # Unnecessary to have the ^2 term, 
# but it gives more striking graph fitting the quadratic term
x2 = x*x
y=log(x)+ rnorm(obs, 0, 1)
plot(x, y)
curve(log(x),from=0,to=1,col=&#39;red&#39;,
      lwd=&#39;2&#39;,ylab=&quot;y&quot;,xlab=&quot;x&quot;,xaxt=&#39;n&#39;,add=TRUE)</code></pre>
<p><img src="/post/2018-06-02-simple-two-line-test-of-u-shape_files/figure-html/Results-1.png" width="672" /></p>
<p>The yellow line is the curve <span class="math inline">\(y=\log{x}\)</span>, and using naked eyes, there is no way it would be close to a U-shape. Now let’s fit a quadratic model <span class="math inline">\(y=\beta_0+\beta_1 x + \beta_2 x^2 +\epsilon\)</span> in the regression, and we get:</p>
<pre class="r"><code>summary(lm(y~x+x2))</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x + x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.4851  -0.7435   0.0933   0.9304   4.5570 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -4.59872    0.02702 -170.19   &lt;2e-16 ***
## x            14.09972    0.16903   83.42   &lt;2e-16 ***
## x2          -10.57034    0.18953  -55.77   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.445 on 9997 degrees of freedom
## Multiple R-squared:  0.5841, Adjusted R-squared:  0.584 
## F-statistic:  7020 on 2 and 9997 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>From the the results, the coefficients on both <span class="math inline">\(x\)</span> and <span class="math inline">\(x^2\)</span> are highly significant. In the plot, we have:</p>
<p><img src="/post/2018-06-02-simple-two-line-test-of-u-shape_files/figure-html/Results1-1.png" width="672" /> In such case, the regression with quadratic term may not be a good choice to test the underlying relationship between <code>x</code> and <code>y</code>. How to fix it?</p>
</div>
<div id="two-lines-approaches" class="section level1">
<h1>Two-lines Approaches</h1>
<p>The idea behind Professor Simonsohn’s two-lines approach is rather simple and intuitive: if <code>x</code> and <code>y</code> truly have U-shape relationship (in the example, it is an inverted U-shape), we should be able to find a cutoff point where <code>x</code> and <code>y</code> should have opposite relationship before and after the point.</p>
<p>Consider the example above. When we fitted the quadratic curve, it implies that if <span class="math inline">\(x &lt;\frac{14.1}{2 * 10.57}=0.67\)</span>, the axis of symmetry, <span class="math inline">\(x\)</span> has a positive relationship with <span class="math inline">\(y\)</span>, and if <span class="math inline">\(x &gt;0.67\)</span>, <span class="math inline">\(x\)</span> has a negative relationship with <span class="math inline">\(y\)</span>, which we know from the data generating process is untrue. Intuitively (the intuition is going to be revisited shortly), we can simply run two linear regressions:</p>
<ul>
<li><span class="math inline">\(y=\beta_0+\beta_1^{1}\cdot x+\epsilon\)</span>, when <span class="math inline">\(x&lt;0.67\)</span></li>
<li><span class="math inline">\(y=\beta_0+\beta_1^{2}\cdot x+\epsilon\)</span>, when <span class="math inline">\(x&gt;0.67\)</span></li>
</ul>
<p>If <span class="math inline">\(\beta_1^{1}\)</span> is positive and <span class="math inline">\(\beta_1^{2}\)</span> is negative, and both coefficients are significant, then we can be more confident that we find an inverted U-shape relationship.</p>
<p>Interestingly, as the author shows in the paper, the quadratic function’s axis of symmetry is not a good option to serve as the cut-off point. He proposed a Robinhood algorithm which would automatically find the cut-off point. In a horse-race simulation test, it gives lowest type-I error rate and highest power (see an <a href="http://webstimate.org/twolines/">online App</a> and corresponding <a href="http://webstimate.org/twolines/twolines_2017_11_28.R">R code</a> in which other researchers can simply upload the data and conduct two-lines test by themselves.).</p>
</div>
<div id="issue-with-discrete-dependent-variable" class="section level1">
<h1>Issue with Discrete Dependent Variable</h1>
<p>One problem with method (the author also pointed in supplimentary materials) is it based on the assumption that independent variable is continuous. However, in many circumstances, the independent variable is a discrete one. Will that create problem? The following example would show that Type-II error may arise.</p>
<p>Suppose this is the data.</p>
<pre class="r"><code>set.seed(343)
N = 30
SD = 6
DT1 = data.frame(x = rep(1, N), y = rnorm(n = N, mean = 1, sd = SD))
DT2 = data.frame(x = rep(2, N), y = rnorm(n = N, mean = 2, sd = SD))
DT3 = data.frame(x = rep(3, N), y = rnorm(n = N/2, mean = 3, sd = SD))
DT4 = data.frame(x = rep(4, N), y = rnorm(n = 20*N, mean = 2, sd = SD))
DT5 = data.frame(x = rep(5, N), y = rnorm(n = N, mean = 1.8, sd = SD))
DT6 = data.frame(x = rep(6, N), y = rnorm(n = N, mean = 1.5, sd = SD))
DT7 = data.frame(x = rep(7, N), y = rnorm(n = N, mean = 1, sd = SD))
DT = rbind(DT1, DT2, DT3, DT4, DT5, DT6, DT7)</code></pre>
<p>If we plot the data, we have:</p>
<p><img src="/post/2018-06-02-simple-two-line-test-of-u-shape_files/figure-html/ShowBarChart-1.png" width="768" /></p>
<p>Pretty good "U-shape" results, huh? But using <code>a= twolines(y ~ x, data = DT)</code>, the twoline test yields insignificant results:</p>
<p><img src="/post/2018-06-02-simple-two-line-test-of-u-shape_files/figure-html/TwoLine-1.png" width="768" /></p>
<p>We may find that the data at <span class="math inline">\(x=4\)</span> were splited to the left line, which results in flatter slope. Ideally, the left line should only include <span class="math inline">\(x=1,2,3\)</span>, and right line only include <span class="math inline">\(x=4,5,6,7\)</span>. In such case, perhaps the simpler way is just run two regressions:</p>
<pre class="r"><code>summary(lm(y~x, data=DT[DT$x&lt;=3,]))</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = DT[DT$x &lt;= 3, ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.9096  -3.3686  -0.1478   3.0677  13.5946 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  -1.7686     1.3892  -1.273   0.2063  
## x             1.6543     0.6431   2.573   0.0118 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.981 on 88 degrees of freedom
## Multiple R-squared:  0.06994,    Adjusted R-squared:  0.05938 
## F-statistic: 6.618 on 1 and 88 DF,  p-value: 0.01177</code></pre>
<pre class="r"><code>summary(lm(y~x, data=DT[DT$x&gt;=4,]))</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = DT[DT$x &gt;= 4, ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -20.0009  -3.7641   0.0881   3.9437  16.0451 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   5.4296     1.3282   4.088 4.87e-05 ***
## x            -0.8765     0.3072  -2.853  0.00446 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.933 on 688 degrees of freedom
## Multiple R-squared:  0.0117, Adjusted R-squared:  0.01026 
## F-statistic: 8.142 on 1 and 688 DF,  p-value: 0.004455</code></pre>
<p>This would result in significant results for both lines.</p>
<p>There are also other limiations of the original two-line method. For example:</p>
<ul>
<li>A bunch of fixed effects I have to control. My economists friends usually have hundreds or thousands fixed effects to control (like controlling each counties’ specific effect in the US.)</li>
<li>The standard errors are serially correlated within certain segments</li>
</ul>
<p>It is less of an issue if we use the <code>felm</code> from <code>lfe</code> package in the regression.</p>
</div>
