---
title: U-Shape Test using "Two Lines"
author: Xing
date: '2017-12-30'
output:
  blogdown::html_page:
    toc: true
slug: u-shape-test-using-two-lines
categories: []
tags:
  - Statistics
  - Clustered Standard Error
  - Econometrics
  - Data
  - Model Selection
---


<div id="TOC">
<ul>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#two-lines-approaches">Two-lines Approaches</a></li>
<li><a href="#regression-with-clustered-standard-errors-and-many-fixed-effects">Regression with Clustered Standard Errors and Many Fixed Effects</a></li>
</ul>
</div>

<p>This post shows how to use Two-lines method to test U-shape relationship, and how to estimate the model with clustered standard errors and many fixed effects.</p>
<div id="motivation" class="section level1">
<h1>Motivation</h1>
<p>In this <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3021690">paper</a> by Uri Simonsohn (2017), the author proposed a noval method to test U-Shape relationship. In the literature, the popular way of testing U-shapeness relationship between <code>x</code> and <code>y</code> is to add a quadratic term in the regression <span class="math inline">\(y=\beta_0+\beta_1 x + \beta_2 x^2 +\epsilon\)</span> (<span class="math inline">\(\epsilon\)</span> is an <em>i.i.d</em> noise). If <span class="math inline">\(\beta_1\)</span> is statistitally significant, then the relationship betewen <code>x</code> and <code>y</code> are U-shape. There are plenty of examples in the real world that two variables have such kind of relationship (consider x = amount of sugar in the icecream, and y = the taste). Simonsohn pointed out that using the quadratic regression would lead to high false positive rate.</p>
<p>I am directly borrowing the example he gave in the paper. Suppose the underlying relationship is <span class="math inline">\(y=\log{x} +\epsilon\)</span>, where <span class="math inline">\(x\sim U[0,1]\)</span>. We first simulate the data and have the following plot:</p>
<pre class="r"><code>set.seed(111)
obs = 10000 # Sample Size of Observations
x = runif(n = obs)^2 # Unnecessary to have the ^2 term, 
# but it gives more striking graph fitting the quadratic term
x2 = x*x
y=log(x)+ rnorm(obs, 0, 1)
plot(x, y)
curve(log(x),from=0,to=1,col=&#39;red&#39;,
      lwd=&#39;2&#39;,ylab=&quot;y&quot;,xlab=&quot;x&quot;,xaxt=&#39;n&#39;,add=TRUE)</code></pre>
<p><img src="/post/2017-12-30-u-shape-test-using-two-lines_files/figure-html/Results-1.png" width="672" /></p>
<p>The yellow line is the curve <span class="math inline">\(y=\log{x}\)</span>, and using naked eyes, there is no way it would be close to a U-shape. Now let’s fit a quadratic model <span class="math inline">\(y=\beta_0+\beta_1 x + \beta_2 x^2 +\epsilon\)</span> in the regression, and we get:</p>
<pre class="r"><code>summary(lm(y~x+x2))</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x + x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.4851  -0.7435   0.0933   0.9304   4.5570 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -4.59872    0.02702 -170.19   &lt;2e-16 ***
## x            14.09972    0.16903   83.42   &lt;2e-16 ***
## x2          -10.57034    0.18953  -55.77   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.445 on 9997 degrees of freedom
## Multiple R-squared:  0.5841, Adjusted R-squared:  0.584 
## F-statistic:  7020 on 2 and 9997 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>From the the results, the coefficients on both <span class="math inline">\(x\)</span> and <span class="math inline">\(x^2\)</span> are highly significant. In the plot, we have:</p>
<p><img src="/post/2017-12-30-u-shape-test-using-two-lines_files/figure-html/Results1-1.png" width="672" /> In such case, the regression with quadratic term may not be a good choice to test the underlying relationship between <code>x</code> and <code>y</code>. How to fix it?</p>
</div>
<div id="two-lines-approaches" class="section level1">
<h1>Two-lines Approaches</h1>
<p>The idea behind Professor Simonsohn’s two-lines approach is rather simple and intuitive: if <code>x</code> and <code>y</code> truly have U-shape relationship (in the example, it is an inverted U-shape), we should be able to find a cutoff point where <code>x</code> and <code>y</code> should have opposite relationship before and after the point.</p>
<p>Consider the example above. When we fitted the quadratic curve, it implies that if <span class="math inline">\(x &lt;\frac{14.1}{2 * 10.57}=0.67\)</span>, the axis of symmetry, <span class="math inline">\(x\)</span> has a positive relationship with <span class="math inline">\(y\)</span>, and if <span class="math inline">\(x &gt;0.67\)</span>, <span class="math inline">\(x\)</span> has a negative relationship with <span class="math inline">\(y\)</span>, which we know from the data generating process is untrue. Intuitively (the intuition is going to be revisited shortly), we can simply run two linear regressions:</p>
<ul>
<li><span class="math inline">\(y=\beta_0+\beta_1^{1}\cdot x+\epsilon\)</span>, when <span class="math inline">\(x&lt;0.67\)</span></li>
<li><span class="math inline">\(y=\beta_0+\beta_1^{2}\cdot x+\epsilon\)</span>, when <span class="math inline">\(x&gt;0.67\)</span></li>
</ul>
<p>If <span class="math inline">\(\beta_1^{1}\)</span> is positive and <span class="math inline">\(\beta_1^{2}\)</span> is negative, and both coefficients are significant, then we can be more confident that we find an inverted U-shape relationship.</p>
<p>Interestingly, as the author shows in the paper, the quadratic function’s axis of symmetry is not a good option to serve as the cut-off point. He proposed a Robinhood algorithm which would automatically find the cut-off point. In a horse-race simulation test, it gives lowest type-I error rate and highest power.</p>
</div>
<div id="regression-with-clustered-standard-errors-and-many-fixed-effects" class="section level1">
<h1>Regression with Clustered Standard Errors and Many Fixed Effects</h1>
<p>The author provides an <a href="http://webstimate.org/twolines/">online App</a> and corresponding <a href="http://webstimate.org/twolines/twolines_2017_11_28.R">R code</a> in which other researchers can simply upload the data and conduct two-lines test by themselves. When I was trying to use the method, I realized that there several issues that the code cannot directly apply to my data. In my own work, I have:</p>
<ul>
<li>A bunch of fixed effects I have to control. My economists friends usually have hundreds or thousands fixed effects to control (like controlling each counties’ specific effect in the US.)</li>
<li>The standard errors are serially correlated within certain segments</li>
</ul>
<p>Hence I break the code so that it can adress this two issues in my own work. Since I was a kid, I enjoyed breaking toys and seeing how things work. In rare case, I could break them and improve the functionality.</p>
</div>
