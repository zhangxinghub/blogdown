<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Xing&#39;s Site</title>
    <link>/post/</link>
    <description>Recent content in Posts on Xing&#39;s Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Zhang Xing</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0800</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>U-Shape Test using &#34;Two Lines&#34;</title>
      <link>/post/u-shape-test-using-two-lines/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/u-shape-test-using-two-lines/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#motivation&#34;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#two-lines-approaches&#34;&gt;Two-lines Approaches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#regression-with-clustered-standard-errors-and-many-fixed-effects&#34;&gt;Regression with Clustered Standard Errors and Many Fixed Effects&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;This post shows how to use Two-lines method to test U-shape relationship, and how to estimate the model with clustered standard errors and many fixed effects.&lt;/p&gt;
&lt;div id=&#34;motivation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;In this &lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3021690&#34;&gt;paper&lt;/a&gt; by Uri Simonsohn (2017), the author proposed a noval method to test U-Shape relationship. In the literature, the popular way of testing U-shapeness relationship between &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; is to add a quadratic term in the regression &lt;span class=&#34;math inline&#34;&gt;\(y=\beta_0+\beta_1 x + \beta_2 x^2 +\epsilon\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is an &lt;em&gt;i.i.d&lt;/em&gt; noise). If &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is statistitally significant, then the relationship betewen &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are U-shape. There are plenty of examples in the real world that two variables have such kind of relationship (consider x = amount of sugar in the icecream, and y = the taste). Simonsohn pointed out that using the quadratic regression would lead to high false positive rate.&lt;/p&gt;
&lt;p&gt;I am directly borrowing the example he gave in the paper. Suppose the underlying relationship is &lt;span class=&#34;math inline&#34;&gt;\(y=\log{x} +\epsilon\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(x\sim U[0,1]\)&lt;/span&gt;. We first simulate the data and have the following plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(111)
obs = 10000 # Sample Size of Observations
x = runif(n = obs)^2 # Unnecessary to have the ^2 term, 
# but it gives more striking graph fitting the quadratic term
x2 = x*x
y=log(x)+ rnorm(obs, 0, 1)
plot(x, y)
curve(log(x),from=0,to=1,col=&amp;#39;red&amp;#39;,
      lwd=&amp;#39;2&amp;#39;,ylab=&amp;quot;y&amp;quot;,xlab=&amp;quot;x&amp;quot;,xaxt=&amp;#39;n&amp;#39;,add=TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-12-30-u-shape-test-using-two-lines_files/figure-html/Results-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The yellow line is the curve &lt;span class=&#34;math inline&#34;&gt;\(y=\log{x}\)&lt;/span&gt;, and using naked eyes, there is no way it would be close to a U-shape. Now let’s fit a quadratic model &lt;span class=&#34;math inline&#34;&gt;\(y=\beta_0+\beta_1 x + \beta_2 x^2 +\epsilon\)&lt;/span&gt; in the regression, and we get:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(lm(y~x+x2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = y ~ x + x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.4851  -0.7435   0.0933   0.9304   4.5570 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  -4.59872    0.02702 -170.19   &amp;lt;2e-16 ***
## x            14.09972    0.16903   83.42   &amp;lt;2e-16 ***
## x2          -10.57034    0.18953  -55.77   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.445 on 9997 degrees of freedom
## Multiple R-squared:  0.5841, Adjusted R-squared:  0.584 
## F-statistic:  7020 on 2 and 9997 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the the results, the coefficients on both &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x^2\)&lt;/span&gt; are highly significant. In the plot, we have:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2017-12-30-u-shape-test-using-two-lines_files/figure-html/Results1-1.png&#34; width=&#34;672&#34; /&gt; In such case, the regression with quadratic term may not be a good choice to test the underlying relationship between &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. How to fix it?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;two-lines-approaches&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Two-lines Approaches&lt;/h1&gt;
&lt;p&gt;The idea behind Professor Simonsohn’s two-lines approach is rather simple and intuitive: if &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; truly have U-shape relationship (in the example, it is an inverted U-shape), we should be able to find a cutoff point where &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; should have opposite relationship before and after the point.&lt;/p&gt;
&lt;p&gt;Consider the example above. When we fitted the quadratic curve, it implies that if &lt;span class=&#34;math inline&#34;&gt;\(x &amp;lt;\frac{14.1}{2 * 10.57}=0.67\)&lt;/span&gt;, the axis of symmetry, &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; has a positive relationship with &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, and if &lt;span class=&#34;math inline&#34;&gt;\(x &amp;gt;0.67\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; has a negative relationship with &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, which we know from the data generating process is untrue. Intuitively (the intuition is going to be revisited shortly), we can simply run two linear regressions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(y=\beta_0+\beta_1^{1}\cdot x+\epsilon\)&lt;/span&gt;, when &lt;span class=&#34;math inline&#34;&gt;\(x&amp;lt;0.67\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(y=\beta_0+\beta_1^{2}\cdot x+\epsilon\)&lt;/span&gt;, when &lt;span class=&#34;math inline&#34;&gt;\(x&amp;gt;0.67\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(\beta_1^{1}\)&lt;/span&gt; is positive and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1^{2}\)&lt;/span&gt; is negative, and both coefficients are significant, then we can be more confident that we find an inverted U-shape relationship.&lt;/p&gt;
&lt;p&gt;Interestingly, as the author shows in the paper, the quadratic function’s axis of symmetry is not a good option to serve as the cut-off point. He proposed a Robinhood algorithm which would automatically find the cut-off point. In a horse-race simulation test, it gives lowest type-I error rate and highest power.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;regression-with-clustered-standard-errors-and-many-fixed-effects&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Regression with Clustered Standard Errors and Many Fixed Effects&lt;/h1&gt;
&lt;p&gt;The author provides an &lt;a href=&#34;http://webstimate.org/twolines/&#34;&gt;online App&lt;/a&gt; and corresponding &lt;a href=&#34;http://webstimate.org/twolines/twolines_2017_11_28.R&#34;&gt;R code&lt;/a&gt; in which other researchers can simply upload the data and conduct two-lines test by themselves. When I was trying to use the method, I realized that there several issues that the code cannot directly apply to my data. In my own work, I have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A bunch of fixed effects I have to control. My economists friends usually have hundreds or thousands fixed effects to control (like controlling each counties’ specific effect in the US.)&lt;/li&gt;
&lt;li&gt;The standard errors are serially correlated within certain segments&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hence I break the code so that it can adress this two issues in my own work. Since I was a kid, I enjoyed breaking toys and seeing how things work. In rare case, I could break them and improve the functionality.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Is it the end of the world if $\alpha=0.005$ is new norm?</title>
      <link>/post/sample-size/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/sample-size/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#how-sample-size-is-determined&#34;&gt;How Sample Size is Determined?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#is-it-the-end-of-the-world-if-alpha-0.005&#34;&gt;Is it the end of the world if &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.005\)&lt;/span&gt;?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;In this &lt;a href=&#34;https://www.nature.com/articles/s41562-017-0189-z&#34;&gt;paper&lt;/a&gt; by Benjamin et al (2017) on redefining statistical significance, they proposed to &lt;strong&gt;change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries.&lt;/strong&gt; That is the proposed p-value is one tenth of the conventional one!! Suppose the world changed to &lt;code&gt;p=0.005&lt;/code&gt;. Do we need &lt;strong&gt;10X&lt;/strong&gt; more sample? As a researcher without sufficient funding, we care about how much additional sample we need suppose our hypothesis is true.&lt;/p&gt;
&lt;p&gt;First let’s review how sample size is calculated. It is really a good review of basic concepts in probability theory and statistics.&lt;/p&gt;
&lt;div id=&#34;how-sample-size-is-determined&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How Sample Size is Determined?&lt;/h1&gt;
&lt;p&gt;First we have to imagine that &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; participants will be randomly assigned into two groups: Treatment (T) and Control (C) group. Assume that there are equal numbers of participants in each group (&lt;span class=&#34;math inline&#34;&gt;\(N_T=N_C\)&lt;/span&gt;). The researcher is interested in testing whether the mean of the distribution &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; in two groups are different. More specifically, the researcher is comparing the two hypotheses:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \mu_T-\mu_C=\mu_0=0\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[H_A: \mu_T-\mu_C =\mu_A \neq 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The researcher is interested in the impact of the treatment on variable &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(X_T\)&lt;/span&gt; denote the sample average of the treatment group, and &lt;span class=&#34;math inline&#34;&gt;\(X_C\)&lt;/span&gt; the sample average of the control group. The significance level is defined as &lt;span class=&#34;math inline&#34;&gt;\(\alpha=Prob(Reject \quad H_0|H_0)\)&lt;/span&gt;. It can be expressed in the following way: &lt;span class=&#34;math inline&#34;&gt;\(\alpha = Prob(X_T-X_C\geq v|H_0)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; is the critical value. For two-sided test &lt;span class=&#34;math inline&#34;&gt;\(\frac{\alpha}{2} = Prob(X_T-X_C\geq v|H_0)\)&lt;/span&gt;. That is, if we want to reject the null hypothesis, the difference &lt;span class=&#34;math inline&#34;&gt;\(X_T-X_C\)&lt;/span&gt; should be large enough. Some simple algebra is needed to derive the critical value:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{\alpha}{2}=Prob(\mu_T-\mu_C\geq v|H_0)\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[=1-Prob(X_T-X_C\leq v|H_0)\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[=1-Prob(\frac{X_T-X_C-\mu_0}{\sigma_N}\leq \frac{v-mu_0}{\sigma_N}|H_0)\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[=1-Prob(\frac{X_T-X_C}{\sigma_N}\leq \frac{v}{\sigma_N}|H_0)\]&lt;/span&gt;(under Null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(\mu_0=0\)&lt;/span&gt;) &lt;span class=&#34;math display&#34;&gt;\[=1-\phi(\frac{v}{\sigma_N})\]&lt;/span&gt;(&lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is standardized normal distribution function)&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(z_{1-\frac{\alpha}{2}}=\frac{v}{\sigma_N}\)&lt;/span&gt;, and then &lt;span class=&#34;math inline&#34;&gt;\(v=z_{1-\frac{\alpha}{2}} \cdot \sigma_N\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since power is defined as the probability of accepting the alternative hypothesis given that the alternative is true &lt;span class=&#34;math inline&#34;&gt;\(1-\beta=Prob(Accept \quad H_A|H_A)=Prob(X_T-X_C\geq v|H_A)\)&lt;/span&gt;, which can be expressed as: &lt;span class=&#34;math display&#34;&gt;\[1-\beta=1-Prob(X_T-X_C\leq z_{1-\frac{\alpha}{2}} \cdot \sigma_N |H_A)\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[=1-Prob(\frac{X_T-X_C-\mu_A}{\sigma_N}\leq \frac{z_{1-\frac{\alpha}{2}} \cdot \sigma_N-\mu_A}{\sigma_N}|H_A)\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[=1-\phi(\frac{z_{1-\frac{\alpha}{2}} \cdot \sigma_N -\mu_A}{\sigma_N})\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[=\phi(\frac{\mu_A}{\sigma_N}-z_{1-\frac{\alpha}{2}})\]&lt;/span&gt; As a result, &lt;span class=&#34;math inline&#34;&gt;\(z_{1-\beta}=\frac{\mu_A}{\sigma_N}-z_{1-\frac{\alpha}{2}}\)&lt;/span&gt;. Under the alternative hypothesis, &lt;span class=&#34;math inline&#34;&gt;\(X_T-X_C \sim N(\mu_A,\sigma^2/n)\)&lt;/span&gt;. Now suppose the variable of interest is binomial distributed. Then &lt;span class=&#34;math inline&#34;&gt;\(\sigma_N=\sqrt{X_T(1-X_T)/N_T + X_C(1-X_C)/N_C}\)&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[\frac{1}{\sqrt{X_T(1-X_T)/N_T + X_C(1-X_C)/N_C}}= \frac{z_{1-\beta}+z_{1-\frac{\alpha}{2}}}{X_T-X_C}\]&lt;/span&gt; $ $&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[N_T=N_C=(X_T(1-X_T)+X_C(1-X_C))\cdot (\frac{z_{1-\beta}+z_{1-\frac{\alpha}{2}}}{X_T-X_C})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Hence, if we want to calculate the sample size, we only need to specify the expected rate/proportion in treatment, the expected rate/proportion in control, power, and the significance level. The code to calculate sample size for binary outcome assuming &lt;span class=&#34;math inline&#34;&gt;\(\alpha= .05\)&lt;/span&gt; is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Calculate Sample Size Based on Binary Outcome
SampleSize = function(PropTreat, PropCont, Power){
  N = ((PropTreat*(1-PropTreat)+PropCont*(1-PropCont))*
    ((qnorm(1-.05/2)+qnorm(1-(1-Power)))^2))/((PropTreat-PropCont)^2)
  return(ceiling(N))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the same logic, we can get the formula to calculate the sample size for normally distributed outcome:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Calculate Sample Size Based on Continuous Outcome
## Two sided test at 0.05 significance level
## kappa is the ratio of the sample size in control and treatment
## SDTreat is the standard deviation 
SampleSizeM = function(MeanTreat, MeanCont, SDTreat, SDCont, Power){
  NTreat =(SDTreat^2+SDCont^2)*
    ((qnorm(1-.05/2)+qnorm(1-(1-Power)))/(MeanTreat-MeanCont))^2
  return(ceiling(NTreat))
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;is-it-the-end-of-the-world-if-alpha-0.005&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Is it the end of the world if &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.005\)&lt;/span&gt;?&lt;/h1&gt;
&lt;p&gt;The original paper gave an answer for this question. It only requires the sample size to increase by &lt;code&gt;70%&lt;/code&gt;. Consider the following senariors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Suppose the rate of response in the control group is 50%, 40%, …,10%;&lt;/li&gt;
&lt;li&gt;Suppose the treatment will reduce 2%, 4%, 6%, and 10% percentage points .&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That is, if the rate of reponse in the control group is 50%, we look at the desired sample size if the treatment will reduce the rate to 48%, 46%, 44%, and 40%. Similar to other base rate. As a result, we will have a &lt;strong&gt;5 X 5&lt;/strong&gt; matrix for respective sample size. We compare difference between the case where &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.005\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;SampleSize05 = function(PropTreat, PropCont, Power){
  N = ((PropTreat*(1-PropTreat)+PropCont*(1-PropCont))*
    ((qnorm(1-.05/2)+qnorm(1-(1-Power)))^2))/((PropTreat-PropCont)^2)
  return(ceiling(N))
}
SampleSize005 = function(PropTreat, PropCont, Power){
  N = ((PropTreat*(1-PropTreat)+PropCont*(1-PropCont))*
    ((qnorm(1-.005/2)+qnorm(1-(1-Power)))^2))/((PropTreat-PropCont)^2)
  return(ceiling(N))
}

pCon = c(0.5,0.4,0.3,0.2,0.1)
Reduced = c(0.02,0.04,0.06,0.08,0.1)
mSampleSiz05 = matrix(NA,nrow=5,ncol=5)
mSampleSiz005 = matrix(NA,nrow=5,ncol=5)
for (i in 1:5){
  for(j in 1:5){
    mSampleSiz05[i,j] = SampleSize05((pCon[i]-Reduced[j]),pCon[i],0.8)
    mSampleSiz005[i,j] = SampleSize005((pCon[i]-Reduced[j]),pCon[i],0.8)

  }
}
(Increased.Sample.Size = (mSampleSiz005-mSampleSiz05)/mSampleSiz05)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]      [,2]      [,3]      [,4]      [,5]
## [1,] 0.6960424 0.6961145 0.6952909 0.6947195 0.6961039
## [2,] 0.6960249 0.6958406 0.6959526 0.6939502 0.6949153
## [3,] 0.6960505 0.6965552 0.6962617 0.6965812 0.6941581
## [4,] 0.6961564 0.6955017 0.6944444 0.6963190 0.6903553
## [5,] 0.6957334 0.6954103 0.6964286 0.6888889 0.6901408&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As can be seen, all are very clost to &lt;code&gt;70%&lt;/code&gt; given different baste rate and different magnitude of effect. From &lt;code&gt;0.05&lt;/code&gt; to &lt;code&gt;0.005&lt;/code&gt;, we do not need 10 times of the sample size.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
