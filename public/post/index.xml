<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Xing&#39;s Site</title>
    <link>/post/</link>
    <description>Recent content in Posts on Xing&#39;s Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Zhang Xing</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0800</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Fake News Consumption and Segregation on Twitter</title>
      <link>/post/fake-news-consumption-and-segregation-on-twitter/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/fake-news-consumption-and-segregation-on-twitter/</guid>
      <description>To form accurate beliefs about the world (e.g., whether the earth is flat or a sphere, whether vaccination causes autism, etc), people must encounter diverse views and opinions which will sometimes contradict their pre-existing views. Many scholars concerned that the emergence of internet especially recent social media reduces the cost of acquiring information from a wide range of sources, facilitating consumers to self-segregate and limit themselves to the information sources that are likely to confirm their views.</description>
    </item>
    
    <item>
      <title>Personalized Data Summary Function Using &#34;data.table&#34;</title>
      <link>/post/personalized-data-summary-function-using-data-table/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/personalized-data-summary-function-using-data-table/</guid>
      <description>One function I miss about Stata is its tabstat. By using just one line code, it can produce very useful summary statistics such as mean, and standard error by groups by conditions. R has its own built-in summary function – summary(), too, but in most cases in my research, I found the summaries produced is barely useful. Consider the following pseudo-data:
library(data.table)set.seed(10)N = 120DT = data.table(x = rnorm(N,1), y = rnorm(N,2),category = sample(letters[1:3], N, replace = T))DT[1:10]## x y category## 1: 1.</description>
    </item>
    
    <item>
      <title>Etiquette of Chatting with the Robot</title>
      <link>/post/etiquette-of-chatting-with-the-robot/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/etiquette-of-chatting-with-the-robot/</guid>
      <description>More and more websites start to use chatbot in their front page. Mostly it serves as a complimentary to search function on the conventional website.</description>
    </item>
    
    <item>
      <title>Is it the end of the world if $\alpha=0.005$ is new norm?</title>
      <link>/post/sample-size/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/sample-size/</guid>
      <description>How Sample Size is Determined?Is it the end of the world if \(\alpha = 0.005\)?In this paper by Benjamin et al (2017) on redefining statistical significance, they proposed to change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries. That is the proposed p-value is one tenth of the conventional one!! Suppose the world changed to p=0.005. Do we need 10X more sample?</description>
    </item>
    
    <item>
      <title>Limited Attention in Response to Email Scam -- A Toy Model</title>
      <link>/post/limited-attention-in-response-to-email-scam-a-toy-model/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/limited-attention-in-response-to-email-scam-a-toy-model/</guid>
      <description>About one year ago or so, I started a project on consumer’s fraud protection issue, especially on how to protect consumers from falling prey to phishing emails – the emails sent by scammers to obtain senstive information such as password, credit card number.
Sequence of the game:
When a user receives an email, the prior belief that the email is unsafe and safe is \(B_{0}\) and \(1-B_{0}\), respectively.The user exerts some effort \(e\) to verify whether the email is safe.</description>
    </item>
    
    <item>
      <title>How much we can learn from Google search data</title>
      <link>/post/how-much-can-we-learn-from-google-search-data/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/how-much-can-we-learn-from-google-search-data/</guid>
      <description>I just finished the book Everybody Lies: Big Data, New Data, and What the Internet Can Tell Us About Who We Really Are by Seth Stephens-Davidowitz, which is a highly rated book. The author devoted a great amount of text to the Google Trends data. My fun part of reading this book is that I could dig the results from the Google Trends website myself.
Here is one example: in the book the author argues that Google search reveals that contemporary American parents are far more focused on their son’s intelligence than on their daughters.</description>
    </item>
    
  </channel>
</rss>