<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Xing&#39;s Site</title>
    <link>/post/</link>
    <description>Recent content in Posts on Xing&#39;s Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Zhang Xing</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0800</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Fake News Consumption and Segregation on Twitter</title>
      <link>/post/fake-news-consumption-and-segregation-on-twitter/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/fake-news-consumption-and-segregation-on-twitter/</guid>
      <description>To form accurate beliefs about the world (e.g., whether the earth is flat or a sphere, whether vaccination causes autism, etc), people must encounter diverse views and opinions which will sometimes contradict their pre-existing views. Many scholars concerned that the emergence of internet especially recent social media reduces the cost of acquiring information from a wide range of sources, facilitating consumers to self-segregate and limit themselves to the information sources that are likely to confirm their views.</description>
    </item>
    
    <item>
      <title>Personalized Data Summary Function Using &#34;data.table&#34;</title>
      <link>/post/personalized-data-summary-function-using-data-table/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/personalized-data-summary-function-using-data-table/</guid>
      <description>One function I miss about Stata is its tabstat. By using just one line code, it can produce very useful summary statistics such as mean, and standard error by groups by conditions. R has its own built-in summary function – summary(), too, but in most cases in my research, I found the summaries produced is barely useful. Consider the following pseudo-data:
library(data.table)set.seed(10)N = 120DT = data.table(x = rnorm(N,1), y = rnorm(N,2),category = sample(letters[1:3], N, replace = T))DT[1:10]## x y category## 1: 1.</description>
    </item>
    
    <item>
      <title>U-Shape Test using &#34;Two Lines&#34;</title>
      <link>/post/u-shape-test-using-two-lines/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/u-shape-test-using-two-lines/</guid>
      <description>MotivationTwo-lines ApproachesRegression with Clustered Standard Errors and Many Fixed EffectsThis post shows how to use Two-lines method to test U-shape relationship, and how to estimate the model with clustered standard errors and many fixed effects.
MotivationIn this paper by Uri Simonsohn (2017), the author proposed a noval method to test U-Shape relationship. In the literature, the popular way of testing U-shapeness relationship between x and y is to add a quadratic term in the regression \(y=\beta_0+\beta_1 x + \beta_2 x^2 +\epsilon\) (\(\epsilon\) is an i.</description>
    </item>
    
    <item>
      <title>Is it the end of the world if $\alpha=0.005$ is the new norm?</title>
      <link>/post/sample-size/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/sample-size/</guid>
      <description>In this paper by Benjamin et al (2017) on redefining statistical significance, they proposed to change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries. That is the proposed p-value is one tenth of the conventional one!! Suppose the world changed to p=0.005. Do we need 10X more sample? As a researcher without sufficient funding, we care about how much additional sample we need suppose our hypothesis is true.</description>
    </item>
    
    <item>
      <title>Anonymize Individuals using digest()</title>
      <link>/post/anonymize-using-digest/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/anonymize-using-digest/</guid>
      <description>When requesting individual level data from others (a company or a government agency), we usually need to properly anomymize the individuals to protect their privacy. The following is an example:
(Data = data.frame(Name = c(&amp;quot;John Smith&amp;quot;, &amp;quot;Jenny Ford&amp;quot;,&amp;quot;Vivian Lee&amp;quot;), Secret = c(&amp;quot;Hate dog&amp;quot;,&amp;quot;Afraid of ghost&amp;quot;,&amp;quot;A bathroom dancer&amp;quot;)))## Name Secret## 1 John Smith Hate dog## 2 Jenny Ford Afraid of ghost## 3 Vivian Lee A bathroom dancerOne simple way is we can just drop the Name, and only keep the Secret since we are more interested in their secrets.</description>
    </item>
    
    <item>
      <title>Limited Attention in Response to Email Scam -- A Toy Model</title>
      <link>/post/limited-attention-in-response-to-email-scam-a-toy-model/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/limited-attention-in-response-to-email-scam-a-toy-model/</guid>
      <description>About one year ago or so, I started a project on consumer’s fraud protection issue, especially on how to protect consumers from falling prey to phishing emails – the emails sent by scammers to obtain senstive information such as password, credit card number. How to model consumer’s response to the scam? Natually I would assume that conusmers have limited attention. That is, paying attention is effortful and costly. More effort the consumer exerts, the more accurate information the consumer will acquire.</description>
    </item>
    
    <item>
      <title>How much we can learn from Google search data</title>
      <link>/post/how-much-can-we-learn-from-google-search-data/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/how-much-can-we-learn-from-google-search-data/</guid>
      <description>I just finished the book Everybody Lies: Big Data, New Data, and What the Internet Can Tell Us About Who We Really Are by Seth Stephens-Davidowitz, which is a highly rated book. The author devoted a great amount of text to the Google Trends data. My fun part of reading this book is that I could dig the results from the Google Trends website myself.
Here is one example: in the book the author argues that Google search reveals that contemporary American parents are far more focused on their son’s intelligence than on their daughters.</description>
    </item>
    
  </channel>
</rss>